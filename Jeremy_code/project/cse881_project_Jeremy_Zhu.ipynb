{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4330cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_tensor:  torch.Size([2480, 1390])\n",
      "labels_tensor:  torch.Size([496])\n",
      "train_indices:  496\n",
      "test_indices:  1984\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from scipy.sparse import load_npz\n",
    "import json\n",
    "\n",
    "adjacency_matrix = load_npz('data_2024/adj.npz')\n",
    "features = np.load('data_2024/features.npy')\n",
    "labels = np.load('data_2024/labels.npy')\n",
    "\n",
    "with open('data_2024/splits.json', 'r') as f:\n",
    "    splits = json.load(f)\n",
    "\n",
    "train_indices = splits['idx_train']\n",
    "test_indices = splits['idx_test']\n",
    "\n",
    "features_tensor = torch.FloatTensor(features)\n",
    "labels_tensor = torch.LongTensor(labels)\n",
    "features_tensor, labels_tensor\n",
    "print(\"features_tensor: \", features_tensor.shape)\n",
    "print(\"labels_tensor: \",labels_tensor.shape)\n",
    "print(\"train_indices: \",len(train_indices))\n",
    "print(\"test_indices: \",len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7748b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index:  torch.Size([2, 10100])\n"
     ]
    }
   ],
   "source": [
    "def adjacency_to_edge_index(adjacency_matrix):\n",
    "    adjacency_coo = adjacency_matrix.tocoo()\n",
    "    # Create the edge index from COO format\n",
    "    row = torch.from_numpy(adjacency_coo.row.astype(np.int64))\n",
    "    col = torch.from_numpy(adjacency_coo.col.astype(np.int64))\n",
    "    #  expect a 2 x Num_edges matrix for edge_index\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "edge_index = adjacency_to_edge_index(adjacency_matrix)\n",
    "print(\"edge_index: \", edge_index.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cf8cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2480, 1390], edge_index=[2, 10100], y=[2480])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "\n",
    "num_nodes = 2480\n",
    "# Assuming features_tensor, edge_index, labels_tensor, train_indices are already defined\n",
    "\n",
    "# Initialize the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Number of node features and classes\n",
    "num_node_features = features_tensor.shape[1]\n",
    "num_classes = labels_tensor.max().item() + 1\n",
    "\n",
    "# Initialize the full-sized labels tensor with placeholders for test nodes\n",
    "padded_labels_tensor = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "padded_labels_tensor[train_indices] = labels_tensor\n",
    "\n",
    "# Create the train mask\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "\n",
    "# Create the Data object with the full-sized labels tensor\n",
    "data = Data(x=features_tensor, edge_index=edge_index, y=padded_labels_tensor)\n",
    "data = data.to(device)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac0b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, num_hidden)\n",
    "        self.conv2 = GCNConv(num_hidden, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e421bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 2, 0, 6, 6, 1, 6, 1, 2, 0, 6, 2, 3, 0, 2, 2, 6, 4, 2, 2, 3, 4, 5,\n",
       "        3, 3, 2, 0, 5, 4, 6, 0, 1, 2, 2, 0, 2, 1, 3, 2, 4, 0, 2, 2, 2, 1, 2, 4,\n",
       "        1, 0, 1, 6, 3, 2, 2, 4, 6, 0, 2, 0, 5, 5, 3, 2, 5, 1, 2, 1, 2, 2, 6, 2,\n",
       "        2, 5, 4, 0, 2, 0, 1, 0, 0, 2, 3, 5, 1, 6, 1, 0, 2, 2, 2, 1, 1, 1, 4, 0,\n",
       "        2, 3, 1, 1, 0, 2, 2, 0, 2, 2, 2, 2, 3, 3, 1, 3, 3, 3, 6, 2, 2, 2, 6, 2,\n",
       "        0, 1, 2, 2, 3, 1, 6, 2, 1, 2, 2, 6, 2, 2, 6, 2, 2, 0, 0, 1, 6, 2, 2, 3,\n",
       "        2, 5, 0, 3, 6, 6, 1, 1, 2, 3, 3, 5, 3, 4, 4, 2, 2, 2, 2, 6, 6, 6, 2, 4,\n",
       "        3, 3, 1, 0, 3, 2, 2, 2, 4, 4, 2, 5, 6, 1, 3, 3, 5, 3, 6, 6, 2, 2, 3, 1,\n",
       "        2, 6, 6, 3, 5, 6, 3, 4, 1, 3, 6, 6, 0, 2, 3, 6, 2, 6, 1, 4, 4, 3, 4, 1,\n",
       "        4, 3, 0, 2, 3, 3, 0, 1, 2, 2, 0, 2, 2, 6, 0, 1, 2, 2, 5, 6, 0, 2, 0, 0,\n",
       "        1, 0, 6, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 1, 2, 0, 6, 1,\n",
       "        6, 2, 3, 6, 6, 6, 2, 4, 4, 0, 0, 4, 0, 4, 4, 4, 4, 6, 6, 3, 1, 1, 2, 2,\n",
       "        2, 5, 6, 2, 3, 3, 3, 3, 3, 2, 2, 6, 2, 6, 2, 4, 2, 1, 2, 2, 2, 2, 2, 3,\n",
       "        0, 3, 4, 2, 3, 3, 1, 2, 6, 3, 2, 1, 2, 0, 1, 2, 3, 4, 1, 1, 2, 4, 6, 6,\n",
       "        5, 6, 2, 0, 1, 1, 0, 3, 1, 3, 6, 6, 5, 6, 3, 5, 3, 2, 2, 5, 0, 0, 4, 3,\n",
       "        3, 2, 4, 5, 1, 1, 1, 1, 1, 1, 1, 6, 1, 3, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 1, 1, 6, 3, 5, 4, 4, 4, 0, 2, 0, 4, 2, 3, 3, 0, 1, 6, 4, 2, 3, 3,\n",
       "        3, 3, 2, 3, 3, 3, 1, 1, 1, 2, 2, 6, 5, 2, 2, 3, 2, 6, 2, 0, 4, 3, 3, 2,\n",
       "        6, 2, 3, 5, 1, 6, 2, 2, 3, 0, 3, 2, 1, 4, 4, 2, 3, 3, 6, 6, 5, 2, 6, 6,\n",
       "        6, 0, 2, 4, 0, 6, 1, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 6, 5, 2, 3, 1, 4, 0,\n",
       "        6, 4, 2, 2, 4, 0, 1, 2, 2, 2, 6, 6, 0, 5, 0, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6439ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Validation accuracy for fold 1: 0.8300\n",
      "Fold 2\n",
      "Validation accuracy for fold 2: 0.7879\n",
      "Fold 3\n",
      "Validation accuracy for fold 3: 0.8182\n",
      "Fold 4\n",
      "Validation accuracy for fold 4: 0.8889\n",
      "Fold 5\n",
      "Validation accuracy for fold 5: 0.8485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the initial setup as before\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert train_indices to a numpy array for easy indexing\n",
    "train_indices_np = np.array(train_indices)\n",
    "\n",
    "# Cross-validation\n",
    "accuracies = []\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_indices_np)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "\n",
    "    # Create masks for the current fold\n",
    "    fold_train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    fold_val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    fold_train_mask[train_indices_np[train_idx]] = True\n",
    "    fold_val_mask[train_indices_np[val_idx]] = True\n",
    "\n",
    "    # Initialize the model and optimizer\n",
    "    model = GCN(num_node_features, 16, num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x.to(device), data.edge_index.to(device))\n",
    "        loss = F.nll_loss(F.log_softmax(out[fold_train_mask], dim=1), data.y[fold_train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x.to(device), data.edge_index.to(device))\n",
    "        preds = out[fold_val_mask].argmax(dim=1)\n",
    "        correct = preds.eq(data.y[fold_val_mask]).sum().item()\n",
    "        total = fold_val_mask.sum().item()\n",
    "        accuracy = correct / total\n",
    "        accuracies.append(accuracy)\n",
    "        print(f\"Validation accuracy for fold {fold+1}: {accuracy:.4f}\")\n",
    "\n",
    "# Train on full training set again\n",
    "model = GCN(num_node_features, 16, num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x.to(device), data.edge_index.to(device))\n",
    "    loss = F.nll_loss(F.log_softmax(out[train_mask], dim=1), data.y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece065d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "# Predict on the full dataset\n",
    "with torch.no_grad():\n",
    "    full_predictions = model(features_tensor.to(device), edge_index.to(device))\n",
    "\n",
    "# Get the predicted classes for the entire dataset\n",
    "full_preds_classes = full_predictions.argmax(dim=1)\n",
    "\n",
    "train_preds_classes = full_preds_classes[train_indices]\n",
    "\n",
    "train_correct = train_preds_classes.eq(labels_tensor.to(device)).sum().item()\n",
    "train_total = len(train_indices)  # or labels_tensor.size(0)\n",
    "train_accuracy = train_correct / train_total\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d18312cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 2,  ..., 4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    full_predictions = model(features_tensor.to(device), edge_index.to(device))\n",
    "\n",
    "# Get the predicted classes for the entire dataset\n",
    "full_preds_classes = full_predictions.argmax(dim=1)\n",
    "\n",
    "# Extract the predictions for the test nodes\n",
    "test_preds_classes = full_preds_classes[test_indices]\n",
    "\n",
    "# The test_preds_classes now contains the predicted classes for the test nodes\n",
    "print(test_preds_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88319439",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('submission_zhu.txt', test_preds_classes, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df799104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
